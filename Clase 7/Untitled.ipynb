{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos desde: DB.txt . . .\n",
      "Datos cargados.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Cargando los datos desde el archivo DB.txt (Noticias de periódico)\n",
    "db = open('DB_twits.txt', 'r', encoding=\"utf-8\")\n",
    "db_data = []\n",
    "db_target = []\n",
    "print('Cargando datos desde: DB.txt . . .')\n",
    "for l in db:\n",
    "    db_data.append(l.split('\\t')[0])\n",
    "    db_target.append(int(l.split('\\t')[1][:-1]))\n",
    "db.close()\n",
    "print('Datos cargados.')\n",
    "#print(db_data[0])\n",
    "#print(db_target)  #Las clases son 1->textos positivos; 0->tetos negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vector = CountVectorizer(ngram_range=(1,2))    #Matriz de términos en documentos\n",
    "# vector = TfidfVectorizer()   #Esquema TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.fit(db_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bow = vector.transform(db_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143, 2454)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = db_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def error_measures(Yestimado, Yteorico):\n",
    "    \n",
    "    CM = confusion_matrix(Yteorico, Yestimado)\n",
    "\n",
    "    TN = CM[0][0]\n",
    "    FN = CM[1][0]\n",
    "    TP = CM[1][1]\n",
    "    FP = CM[0][1]\n",
    "    \n",
    "    sens = TP/(TP+FN)\n",
    "    esp = TN/(TN+FP)\n",
    "    \n",
    "    return sens, esp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def results(Xtrain, Xtest, acc, sens, esp, model):\n",
    "    print(\"\\nResultados con \" + model + \"\\n\")\n",
    "    print(\"Accuracy: \", np.mean(acc), \"+/-\", np.std(acc))\n",
    "    print(\"Sensitivity: \", np.mean(sens), \"+/-\", np.std(sens))\n",
    "    print(\"Especificity: \", np.mean(esp), \"+/-\", np.std(esp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados con Regresion Logistica (Lineal)\n",
      "\n",
      "Accuracy:  0.65 +/- 0.080027001616\n",
      "Sensitivity:  0.0139932567433 +/- 0.0386404965807\n",
      "Especificity:  0.999655172414 +/- 0.00343099116244\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression()\n",
    "acc = []\n",
    "sens = []\n",
    "esp = []\n",
    "\n",
    "for i in range(100):\n",
    "    \n",
    "    Xtrain,Xtest,Ytrain,Ytest = train_test_split(bow,y)   #Realiza una única partición\n",
    "                                                          #de la base de datos.\n",
    "    \n",
    "    lr.fit(Xtrain,Ytrain)\n",
    "    Yest = lr.predict(Xtest)\n",
    "    s, e = error_measures(Yest,Ytest)\n",
    "    sens.append(s); esp.append(e)\n",
    "    acc.append(lr.score(Xtest,Ytest))\n",
    "\n",
    "results(Xtrain, Xtest, acc, sens, esp, \"Regresion Logistica\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados con KNN Neighborhood\n",
      "\n",
      "Accuracy:  0.683888888889 +/- 0.0719846519993\n",
      "Sensitivity:  0.193289235275 +/- 0.133054969416\n",
      "Especificity:  0.955980858135 +/- 0.0432306658372\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "\n",
    "knn=KNN(n_neighbors=1)\n",
    "acc = []\n",
    "sens = []\n",
    "esp = []\n",
    "\n",
    "for i in range(100):\n",
    "    Xtrain,Xtest,Ytrain,Ytest = train_test_split(bow,y)\n",
    "\n",
    "    knn.fit(Xtrain, Ytrain)\n",
    "    Yest = knn.predict(Xtest)\n",
    "    s, e = error_measures(Yest,Ytest)\n",
    "    sens.append(s); esp.append(e)\n",
    "    acc.append(knn.score(Xtest,Ytest))\n",
    "results(Xtrain, Xtest, acc, sens, esp, \"KNN Neighborhood\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados con Árbol de decisión\n",
      "\n",
      "Accuracy:  0.651666666667 +/- 0.0787067537535\n",
      "Sensitivity:  0.348832259717 +/- 0.105542350254\n",
      "Especificity:  0.960252444273 +/- 0.0362309112745\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier as DT\n",
    "\n",
    "clf = DT(random_state=0)\n",
    "\n",
    "acc = []\n",
    "sens = []\n",
    "esp = []\n",
    "\n",
    "for i in range(100):\n",
    "    Xtrain,Xtest,Ytrain,Ytest = train_test_split(bow,y)\n",
    "\n",
    "    clf.fit(Xtrain, Ytrain)\n",
    "    Yest = knn.predict(Xtest)\n",
    "    s, e = error_measures(Yest,Ytest)\n",
    "    sens.append(s); esp.append(e)\n",
    "    acc.append(clf.score(Xtest,Ytest))\n",
    "\n",
    "#Complete el código para Árboles de decisión\n",
    "\n",
    "print(\"Resultados con Árbol de decisión\\n\")\n",
    "print(\"Accuracy: \", np.mean(acc), \"+/-\", np.std(acc))\n",
    "print(\"Sensitivity: \", np.mean(sens), \"+/-\", np.std(sens))\n",
    "print(\"Especificity: \", np.mean(esp), \"+/-\", np.std(esp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
